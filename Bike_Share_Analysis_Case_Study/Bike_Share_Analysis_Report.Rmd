---
title: "Bike_Share_Analysis_Report"
author: "Hannan Khan"
date: "2/16/2022"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Report Outline
* [Current Status](#current-status)
* [Business Task](#business-task)
* [Data Sources](#data-sources)
* [Data Cleaning](#data-cleaning)
* [Data Preparation-Processing](#data-preparation-processing)
* [Analysis](#analysis)
* [Actions](#actions)
* [Appendix](#appendix)

## Current Status

The company `Cyclistic` offers a bike-share service to a network of 692 stations in Chicago. There are three types of pricing plans:

* single-ride pass
* full-day pass
* annual membership

**Casual riders:** customers who use single-ride or full-day passes.  
**Annual members:** customers who purchase annual memberships.  
  
Finance analysts at `Cyclistic` have determined that annual members are more profitable than casual riders.

## Business Task
The current goal of `Cyclistic` is to develop marketing strategies that will convert casual riders into annual members. In order for that to happen, *the marketing team needs to understand how casual riders differ from annual members.*  
**This report analyzes how casual riders and annual members use Cyclistic bikes differently using data from last year, 2021.**

## Data Sources
The data is publicly available [here](https://ride.divvybikes.com/system-data) from the source company Divvy, designated as `Cyclistic` in this report. The data is provided under this [license](https://ride.divvybikes.com/data-license-agreement).
The data is provided by the month, and contains anonymized information about:

* Trip start datetime
* Trip end datetime
* Trip start station
* Trip end station
* Trip start latitude/longitude
* Trip end latitude/longitude
* Rider membership type
* Bicycle type

The dataset in question is:

* _Reliable_: From the source company `Cyclistic` itself.
* _Original_: This is novel data.
* _Comprehensive_: This data covers enough features for us to analyze how casual riders and annual members differ.
* _Current_: Covers the previous year, 2021.
* _Cited_: see [Data Sources](#data-sources)

## Data Cleaning
The data was concatenated using [this](https://github.com/hannankhan888/Data_Science_Portfolio/blob/main/Bike_Share_Analysis_Case_Study/data_concatenation.ipynb) Jupyter Notebook.  

```{r loading libraries, results = 'hide'}
library(tidyverse)
library(janitor)
library(lubridate)
```

Since the 2021 data is now all in one file, we can load it and take a peek at its structure:
```{r loading dataset}
df <- read_csv("D:\\Datasets\\Divvy_Trips_Data\\Divvy_Trips_2021\\2021_all_data.csv")
str(df)
```

We rename the "...1" column and make sure that all columns have consistent nomenclature:
```{r renaming columns}
df <- rename(df, index = "...1")
colnames(df)
clean_names(df)
```
Lets make sure our datetime columns are formatted as such:
```{r formatting datetime columns}
df[["started_at"]] <- as.POSIXct(df[["started_at"]],
                                 format = "%Y-%m-%d %H:%M:%S")
df[["ended_at"]] <- as.POSIXct(df[["ended_at"]],
                               format = "%Y-%m-%d %H:%M:%S")

# lets check to see if the formatting has worked:
sapply(df, class)
```


We look at null values for our data frame by column:
```{r checking for null values}
colSums(is.na.data.frame(df))
```

We have a lot of null values in certain columns. Let's get rid of the values in the largest column (end_station_name):
```{r removing null values}
df <- drop_na(df, end_station_name)

# checking to see if na values are dropped:
colSums(is.na.data.frame(df))
```

We still have around 270k null values, so we keep cleaning:
```{r removing null values again}
df <- drop_na(df, start_station_name)

# check again to see if na values are dropped:
colSums(is.na.data.frame(df))
```

Great! Now the data frame is free of null values.  
We can proceed to check for duplicates in the data. Since the ride_id is a primary key, we can use that to see if we have any duplicates in our data:
```{r checking for duplicates}
get_dupes(df, ride_id)
```

Now our data is:

* Correctly named
* Correctly formatted
* Free of null values
* Free of duplicates

The steps taken above verify the dataset's integrity.  
In terms of bias, this does not seem to be an issue with the dataset. All bike rides are included (except those taken by service staff as they would skew the data), and each ride is anonymized.  
In terms of how this data will help us answer the business task, we will need to engineer some new features in the next section.

## Data Preparation-Processing





## Analysis
## Actions
## Appendix
| Description | File |
|    :----   | :---: |
| Jupyter notebook used for data concatenation. | [data_concatenation.ipynb](https://github.com/hannankhan888/Data_Science_Portfolio/blob/main/Bike_Share_Analysis_Case_Study/data_concatenation.ipynb) |
| General analysis/scratch file script. | [Bike_Share_Analysis.R](https://github.com/hannankhan888/Data_Science_Portfolio/blob/main/Bike_Share_Analysis_Case_Study/Bike_Share_Analysis.R) |
| This report in R markdown notebook format. | [Bike_Share_Analysis_Report.Rmd](https://github.com/hannankhan888/Data_Science_Portfolio/blob/main/Bike_Share_Analysis_Case_Study/Bike_Share_Analysis_Report.Rmd) |





